{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Káº¿t ná»‘i vá»›i drive"],"metadata":{"id":"4OTUSRkg5ZFR"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/MyDrive')"],"metadata":{"id":"8kLfGeyt5iOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/New_Model"],"metadata":{"id":"rzd-HL517fNN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.Preparing Dataset"],"metadata":{"id":"F0zbMExg57-O"}},{"cell_type":"code","source":["!pip install roboflow"],"metadata":{"id":"4RBVAc3H-2Sf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"ne260jhdcPwi9nRfFYUP\")\n","project = rf.workspace(\"bach-khoa-da-nang-8bvyc\").project(\"plate-number-770\")\n","dataset = project.version(4).download(\"yolov8\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8t66nJTV8T64","outputId":"c785f743-2072-47b5-925a-17c2d9a83076"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in plate-number-770-4 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60203/60203 [00:04<00:00, 13415.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to plate-number-770-4 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2101/2101 [00:00<00:00, 7271.59it/s]\n"]}]},{"cell_type":"markdown","source":["**Config láº¡i file .yaml**"],"metadata":{"id":"yIy8KE2A9hLD"}},{"cell_type":"markdown","source":["names:\n","- plate number\n","nc: 1\n","roboflow:\n","  license: CC BY 4.0\n","  project: plate-number-770\n","  url: https://universe.roboflow.com/bach-khoa-da-nang-8bvyc/plate-number-770/dataset/4\n","  version: 4\n","  workspace: bach-khoa-da-nang-8bvyc\n","test: ../test/images\n","train: /content/plate-number-770-4/train/images\n","val: /content/plate-number-770-4/valid\n"],"metadata":{"id":"rmmTBJ7lWlrJ"}},{"cell_type":"markdown","source":["# 2. Install YOLOv8"],"metadata":{"id":"EEwMYQOz9v50"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JKku_VN5Xs3","outputId":"1ab3594b-433c-45a0-c787-5504dd2d1aa1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.0.222-py3-none-any.whl (653 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/654.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.6/654.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m645.1/654.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m654.0/654.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.45.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.222\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a model\n","import os\n","from IPython.display import display, Image\n","from IPython import display\n","display.clear_output()\n","!yolo mode=checks"],"metadata":{"id":"8ru4WN5aZ_DQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc7d3ce9-41d7-4355-a4b4-7decb9e170a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 395, in entrypoint\n","    raise ValueError(f\"Invalid 'mode={mode}'. Valid modes are {MODES}.\\n{CLI_HELP_MSG}\")\n","ValueError: Invalid 'mode=<module 'ultralytics.utils.checks' from '/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py'>'. Valid modes are ('train', 'val', 'predict', 'export', 'track', 'benchmark').\n","\n","    Arguments received: ['yolo', 'mode=checks']. Ultralytics 'yolo' commands use the following syntax:\n","\n","        yolo TASK MODE ARGS\n","\n","        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n","                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n","                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n","\n","    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n","        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n","\n","    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n","        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n","\n","    3. Val a pretrained detection model at batch-size 1 and image size 640:\n","        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n","\n","    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n","        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n","\n","    5. Run special commands:\n","        yolo help\n","        yolo checks\n","        yolo version\n","        yolo settings\n","        yolo copy-cfg\n","        yolo cfg\n","\n","    Docs: https://docs.ultralytics.com\n","    Community: https://community.ultralytics.com\n","    GitHub: https://github.com/ultralytics/ultralytics\n","    \n"]}]},{"cell_type":"markdown","source":["# 3. Training\n"],"metadata":{"id":"5rQbtNhkkaH_"}},{"cell_type":"code","source":["!yolo task=detect mode=train model=yolov8m.pt data={dataset.location}/data.yaml epochs=30 imgsz=640"],"metadata":{"id":"hwfeGxSvZ_RY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9705dcb2-56a6-4316-d1f0-f5e7f6381f7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.222 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/plate-number-770-4/data.yaml, epochs=30, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 4.30MB/s]\n","2023-12-06 02:56:39.670611: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-06 02:56:39.670680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-06 02:56:39.670729: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n","Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n","\n","Transferred 469/475 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 24.5MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/plate-number-770-4/train/labels... 837 images, 0 backgrounds, 0 corrupt: 100% 837/837 [00:00<00:00, 2250.21it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/plate-number-770-4/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/plate-number-770-4/valid/labels... 209 images, 0 backgrounds, 0 corrupt: 100% 209/209 [00:00<00:00, 1581.92it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/plate-number-770-4/valid/labels.cache\n","Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/30      6.87G     0.9186      1.304      1.162          7        640: 100% 53/53 [00:29<00:00,  1.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:05<00:00,  1.34it/s]\n","                   all        209        209    0.00309      0.426    0.00219   0.000949\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/30      7.08G      1.048     0.8908      1.279         11        640: 100% 53/53 [00:26<00:00,  2.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.70it/s]\n","                   all        209        209   0.000373     0.0766   0.000147   5.82e-05\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/30      7.08G      1.021     0.7974      1.236          7        640: 100% 53/53 [00:26<00:00,  2.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.83it/s]\n","                   all        209        209    0.00452    0.00478   0.000171    2.5e-05\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/30      7.11G      1.024     0.7959      1.242          9        640: 100% 53/53 [00:28<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.25it/s]\n","                   all        209        209      0.824       0.67      0.757      0.535\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/30      7.12G      1.025     0.8149      1.258         10        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.85it/s]\n","                   all        209        209      0.643      0.699      0.725      0.527\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/30      7.08G     0.9182     0.6734      1.151          8        640: 100% 53/53 [00:26<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.31it/s]\n","                   all        209        209      0.928      0.928      0.975      0.736\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/30      7.11G     0.8886     0.6505      1.148          8        640: 100% 53/53 [00:27<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.26it/s]\n","                   all        209        209      0.931      0.961      0.989      0.807\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/30      7.12G     0.8688     0.6134      1.128          4        640: 100% 53/53 [00:27<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.33it/s]\n","                   all        209        209      0.971      0.954      0.991        0.8\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/30      7.13G     0.8588     0.5928      1.127         14        640: 100% 53/53 [00:27<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.04it/s]\n","                   all        209        209      0.941      0.957      0.989      0.812\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/30      7.07G     0.8304     0.5718      1.101         14        640: 100% 53/53 [00:27<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.83it/s]\n","                   all        209        209      0.947      0.944      0.974      0.803\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/30      7.11G     0.7809     0.5428      1.088          9        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.76it/s]\n","                   all        209        209      0.967       0.98      0.991      0.852\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/30      7.11G     0.7902     0.5272      1.081          8        640: 100% 53/53 [00:26<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.72it/s]\n","                   all        209        209      0.963      0.967      0.991      0.856\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/30      7.11G      0.744     0.5153       1.07         12        640: 100% 53/53 [00:27<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.75it/s]\n","                   all        209        209      0.952      0.952      0.982       0.84\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/30      7.08G     0.7308     0.4895      1.046          7        640: 100% 53/53 [00:27<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.14it/s]\n","                   all        209        209      0.975      0.944       0.99      0.854\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/30       7.1G     0.7201     0.4675      1.058          9        640: 100% 53/53 [00:27<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.33it/s]\n","                   all        209        209      0.981      0.995      0.994      0.868\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/30      7.13G     0.6769     0.4477      1.022          9        640: 100% 53/53 [00:27<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.26it/s]\n","                   all        209        209      0.967      0.975      0.992       0.87\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/30      7.13G     0.6706     0.4391      1.003          9        640: 100% 53/53 [00:27<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.32it/s]\n","                   all        209        209      0.952      0.986      0.992      0.883\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/30      7.08G     0.6698     0.4435      1.027         11        640: 100% 53/53 [00:27<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.02it/s]\n","                   all        209        209       0.99      0.967      0.992      0.882\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/30      7.11G     0.6486     0.4189      1.011         10        640: 100% 53/53 [00:26<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.79it/s]\n","                   all        209        209      0.958       0.99      0.993      0.896\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/30      7.11G     0.6133     0.4107     0.9982         10        640: 100% 53/53 [00:26<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.77it/s]\n","                   all        209        209      0.976       0.96      0.993       0.89\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/30      7.12G     0.5712     0.3676      0.984          5        640: 100% 53/53 [00:27<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.99it/s]\n","                   all        209        209       0.99      0.969      0.994      0.904\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/30      7.08G     0.5521     0.3533      0.953          5        640: 100% 53/53 [00:26<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.33it/s]\n","                   all        209        209      0.981      0.988      0.994      0.906\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/30      7.11G     0.5297      0.342     0.9463          5        640: 100% 53/53 [00:26<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.62it/s]\n","                   all        209        209      0.981      0.997      0.994      0.909\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/30      7.11G     0.5368     0.3265     0.9473          5        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.69it/s]\n","                   all        209        209      0.976          1      0.993      0.912\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/30      7.13G     0.5105     0.3131     0.9127          5        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.80it/s]\n","                   all        209        209       0.99      0.996      0.995      0.919\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/30      7.08G     0.4998     0.3088     0.9152          5        640: 100% 53/53 [00:26<00:00,  2.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.12it/s]\n","                   all        209        209       0.99       0.99      0.994       0.92\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/30      7.11G     0.4813     0.2967     0.9119          5        640: 100% 53/53 [00:26<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.32it/s]\n","                   all        209        209          1       0.99      0.995      0.917\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/30      7.11G      0.471     0.2856     0.9071          5        640: 100% 53/53 [00:27<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.35it/s]\n","                   all        209        209      0.995      0.989      0.995      0.926\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/30      7.12G     0.4746     0.2739     0.9057          5        640: 100% 53/53 [00:27<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.11it/s]\n","                   all        209        209      0.994      0.986      0.995      0.927\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/30      7.07G     0.4576     0.2659     0.8988          5        640: 100% 53/53 [00:27<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.85it/s]\n","                   all        209        209       0.99       0.99      0.995      0.928\n","\n","30 epochs completed in 0.281 hours.\n","Optimizer stripped from runs/detect/train2/weights/last.pt, 52.0MB\n","Optimizer stripped from runs/detect/train2/weights/best.pt, 52.0MB\n","\n","Validating runs/detect/train2/weights/best.pt...\n","Ultralytics YOLOv8.0.222 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:05<00:00,  1.31it/s]\n","                   all        209        209       0.99       0.99      0.995      0.928\n","Speed: 0.5ms preprocess, 11.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"markdown","source":["# 5. Training next"],"metadata":{"id":"BX4YSydHHnsp"}},{"cell_type":"code","source":["!yolo task=detect mode=train model=/content/runs/detect/train3/weights/last.pt data={dataset.location}/data.yaml epochs=20 imgsz=640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vz60Cx2Hrr8","outputId":"5056df2d-4cbf-429c-dda0-6f97654b6f50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.222 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/runs/detect/train3/weights/last.pt, data=/content/plate-number-770-4/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n","2023-12-06 03:58:48.784268: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-06 03:58:48.784335: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-06 03:58:48.784386: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n","Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/plate-number-770-4/train/labels.cache... 837 images, 0 backgrounds, 0 corrupt: 100% 837/837 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/plate-number-770-4/valid/labels.cache... 209 images, 0 backgrounds, 0 corrupt: 100% 209/209 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train4/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train4\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/20      6.87G     0.5493     0.3638     0.9614          7        640: 100% 53/53 [00:28<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.70it/s]\n","                   all        209        209      0.992      0.986      0.995      0.901\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/20      7.07G     0.6175      0.399      1.002         11        640: 100% 53/53 [00:26<00:00,  2.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.85it/s]\n","                   all        209        209      0.972      0.983      0.994      0.882\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/20      7.07G     0.6125     0.4146     0.9973          7        640: 100% 53/53 [00:26<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.27it/s]\n","                   all        209        209      0.893      0.952      0.955      0.798\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/20      7.11G     0.6743     0.4378      1.022          9        640: 100% 53/53 [00:27<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.31it/s]\n","                   all        209        209      0.958      0.947      0.988      0.844\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/20      7.12G      0.681     0.4598      1.051         10        640: 100% 53/53 [00:27<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.30it/s]\n","                   all        209        209      0.971      0.964      0.992      0.864\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/20      7.08G     0.6442     0.4301     0.9986          8        640: 100% 53/53 [00:27<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.81it/s]\n","                   all        209        209      0.984      0.967      0.993      0.872\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/20      7.09G     0.6472     0.4299      1.017          8        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.80it/s]\n","                   all        209        209      0.988      0.986      0.994      0.875\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/20      7.11G     0.6567     0.4167      1.007          4        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.18it/s]\n","                   all        209        209       0.99      0.976      0.994      0.896\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/20      7.11G     0.6212     0.4086      1.005         14        640: 100% 53/53 [00:27<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.11it/s]\n","                   all        209        209      0.979       0.99      0.994      0.871\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/20      7.07G     0.6318     0.3975     0.9917         14        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.19it/s]\n","                   all        209        209      0.986      0.977      0.994      0.878\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/20      7.11G     0.5371     0.3325     0.9454          5        640: 100% 53/53 [00:28<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.92it/s]\n","                   all        209        209      0.986      0.981      0.994      0.893\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/20      7.12G     0.5193     0.3294     0.9352          5        640: 100% 53/53 [00:26<00:00,  2.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.89it/s]\n","                   all        209        209      0.987      0.995      0.995      0.901\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/20      7.11G     0.5083     0.3197     0.9265          5        640: 100% 53/53 [00:26<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.93it/s]\n","                   all        209        209      0.981      0.992      0.994      0.911\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/20      7.07G     0.4888     0.2975     0.8956          5        640: 100% 53/53 [00:26<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.98it/s]\n","                   all        209        209      0.995      0.998      0.995      0.915\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/20       7.1G     0.4795     0.2824     0.9038          5        640: 100% 53/53 [00:26<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.96it/s]\n","                   all        209        209      0.987      0.995      0.994      0.918\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/20      7.11G     0.4784     0.2723     0.8888          5        640: 100% 53/53 [00:26<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.04it/s]\n","                   all        209        209          1      0.994      0.995      0.928\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/20      7.12G     0.4579     0.2685     0.8875          5        640: 100% 53/53 [00:26<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.25it/s]\n","                   all        209        209      0.992          1      0.995      0.923\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/20      7.06G     0.4863     0.2705     0.8848          5        640: 100% 53/53 [00:26<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.01it/s]\n","                   all        209        209      0.991          1      0.995      0.925\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/20       7.1G     0.4493     0.2582     0.8793          5        640: 100% 53/53 [00:27<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.06it/s]\n","                   all        209        209      0.993          1      0.995      0.938\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/20       7.1G     0.4243     0.2393      0.854          5        640: 100% 53/53 [00:27<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.32it/s]\n","                   all        209        209      0.994          1      0.995      0.934\n","\n","20 epochs completed in 0.183 hours.\n","Optimizer stripped from runs/detect/train4/weights/last.pt, 52.0MB\n","Optimizer stripped from runs/detect/train4/weights/best.pt, 52.0MB\n","\n","Validating runs/detect/train4/weights/best.pt...\n","Ultralytics YOLOv8.0.222 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:06<00:00,  1.06it/s]\n","                   all        209        209      0.993          1      0.995      0.937\n","Speed: 0.5ms preprocess, 10.3ms inference, 0.0ms loss, 4.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train4\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"markdown","source":["# 4. Validating"],"metadata":{"id":"n1_p70a5_0du"}},{"cell_type":"code","source":["!yolo task=detect mode=val model=/content/drive/MyDrive/New_Model/train4/weights/best.pt data=/content/plate-number-770-4/data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58-PeuSL_3Pe","outputId":"5ccc2a71-2a6e-4091-aaf5-659bcb6d04f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.222 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/plate-number-770-4/valid/labels.cache... 209 images, 0 backgrounds, 0 corrupt: 100% 209/209 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:08<00:00,  1.68it/s]\n","                   all        209        209      0.993          1      0.995      0.937\n","Speed: 4.3ms preprocess, 22.9ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val3\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"markdown","source":["# 5. Predict"],"metadata":{"id":"ddkDuSv8KwOG"}},{"cell_type":"code","source":["# Upload anh truc tiep\n","from google.colab import files\n","\n","upload = files.upload()\n","filename = next(iter(upload))\n","\n","print(f\"Da tai len file : {filename}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"y6VWF7KCKyPI","outputId":"64365f29-ee95-4502-a340-2b8898dc8729"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-cf385993-df63-4e73-a27e-1e48ffb27372\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cf385993-df63-4e73-a27e-1e48ffb27372\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving mercedesg-63-bienvang-2-1602118706450.png to mercedesg-63-bienvang-2-1602118706450.png\n","Da tai len file : mercedesg-63-bienvang-2-1602118706450.png\n"]}]},{"cell_type":"code","source":["# Predict with CLI\n","!yolo task=detect mode=predict model=/content/drive/MyDrive/New_Model/train4/weights/best.pt source='/content/mercedesg-63-bienvang-2-1602118706450.png'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66l4pz4VLQ-F","outputId":"21d00b67-7d5d-4efa-96c3-5b727703b788"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.222 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n","\n","image 1/1 /content/mercedesg-63-bienvang-2-1602118706450.png: 640x608 1 plate number, 109.0ms\n","Speed: 3.6ms preprocess, 109.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 608)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"]}]}]}